{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "c:\\users\\phil\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#this pulls the value of k, containing the number of channels in the output of the cnn layer, and pad_size1, pad_size2, the size of the paddings\n",
    "#output_size, output_size2, and learning_rate\n",
    "%run config.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotLayer(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, num_units, W=lasagne.init.Normal(0.01), **kwargs):\n",
    "        super(DotLayer, self).__init__(incoming, **kwargs)\n",
    "        num_inputs = self.input_shape[1]\n",
    "        self.num_units = num_units\n",
    "        self.W = self.add_param(W, (num_inputs, num_units), name='W')\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return T.dot(input, self.W)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.num_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer(lasagne.layers.Layer):\n",
    "    \n",
    "    def get_output_for(self, incoming):\n",
    "\n",
    "        l_hidden_1 = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k, filter_size=(3, 3), pad = 'same',\n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform(), name = 'base')\n",
    "\n",
    "\n",
    "        l_batch_1 = lasagne.layers.BatchNormLayer(l_hidden_1)\n",
    "\n",
    "\n",
    "        l_relu_1 = lasagne.layers.NonlinearityLayer(l_batch_1, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "        \n",
    "        return l_relu_1\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], k, 6, 7)\n",
    "\n",
    "\n",
    "    \n",
    "def BaseLayerf(incoming):\n",
    "    l_hidden_1 = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k, filter_size=(3, 3), pad = 'same',\n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform(), name = 'base')\n",
    "\n",
    "\n",
    "    l_batch_1 = lasagne.layers.BatchNormLayer(l_hidden_1)\n",
    "\n",
    "\n",
    "    l_relu_1 = lasagne.layers.NonlinearityLayer(l_batch_1, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    return l_relu_1     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SkipLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input1, input2):\n",
    "        return input1 + input2\n",
    "\n",
    "def SkipLayerf(incoming1, incoming2):\n",
    "    return incoming1 + incoming2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, incoming):\n",
    "        l_resid_1a = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k, filter_size=(3, 3), pad = 'same', \n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform(), name = 'resid')\n",
    "\n",
    "        l_resid_1b = lasagne.layers.BatchNormLayer(l_resid_1a)\n",
    "\n",
    "        l_resid_1c = lasagne.layers.NonlinearityLayer(l_resid_1b, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "        l_resid_1d = lasagne.layers.Conv2DLayer(\n",
    "              l_resid_1c, num_filters=k, filter_size=(3, 3), pad = 'same', \n",
    "              nonlinearity=None,\n",
    "              W=lasagne.init.GlorotUniform())\n",
    "\n",
    "        l_resid_1e = lasagne.layers.BatchNormLayer(l_resid_1d)\n",
    "\n",
    "        #l_resid_1f = lasgane.layers.SkipLayer(l_resid_1e, l_resid_1a)\n",
    "        l_resid_1f = lasagne.layers.ElemwiseSumLayer([l_resid_1e, l_resid_1a])\n",
    "        \n",
    "        l_resid_1g = lasagne.layers.NonlinearityLayer(l_resid_1f, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "        return l_resid_1f\n",
    "    \n",
    "def ResidualBlockLayerf(incoming):\n",
    "    l_resid_1a = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k, filter_size=(3, 3), pad = 'same', \n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform(), name = 'resid')\n",
    "\n",
    "    l_resid_1b = lasagne.layers.BatchNormLayer(l_resid_1a)\n",
    "\n",
    "    l_resid_1c = lasagne.layers.NonlinearityLayer(l_resid_1b, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_resid_1d = lasagne.layers.Conv2DLayer(\n",
    "          l_resid_1c, num_filters=k, filter_size=(3, 3), pad = 'same', \n",
    "          nonlinearity=None,\n",
    "          W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    l_resid_1e = lasagne.layers.BatchNormLayer(l_resid_1d)\n",
    "\n",
    "    #l_resid_1f = lasgane.layers.SkipLayer(l_resid_1e, l_resid_1a)\n",
    "    l_resid_1f = lasagne.layers.ElemwiseSumLayer([l_resid_1e, l_resid_1a])\n",
    "\n",
    "    l_resid_1g = lasagne.layers.NonlinearityLayer(l_resid_1f, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    return l_resid_1f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualTowerLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, incoming):\n",
    "        \n",
    "        l_hid_1 = ResidualBlockLayerf(incoming)\n",
    "        \n",
    "        l_hid_2 = ResidualBlockLayerf(l_hid_1)\n",
    "\n",
    "        l_hid_3 = ResidualBlockLayerf(l_hid_2)\n",
    "\n",
    "        l_hid_4 = ResidualBlockLayerf(l_hid_3)\n",
    "\n",
    "        l_hid_5 = ResidualBlockLayerf(l_hid_4)\n",
    "\n",
    "        l_hid_6 = ResidualBlockLayerf(l_hid_5)\n",
    "        \n",
    "        return l_hid_6\n",
    "\n",
    "def ResidualTowerLayerf(incoming):\n",
    "    l_hid_1 = ResidualBlockLayerf(incoming)\n",
    "        \n",
    "    l_hid_2 = ResidualBlockLayerf(l_hid_1)\n",
    "\n",
    "    l_hid_3 = ResidualBlockLayerf(l_hid_2)\n",
    "\n",
    "    l_hid_4 = ResidualBlockLayerf(l_hid_3)\n",
    "\n",
    "    l_hid_5 = ResidualBlockLayerf(l_hid_4)\n",
    "\n",
    "    l_hid_6 = ResidualBlockLayerf(l_hid_5)\n",
    "\n",
    "    return l_hid_6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionHeadLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, incoming):\n",
    "        l_action_head_a = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k2, filter_size=(1,1), pad = 'same', untie_biases = False,\n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "        l_action_head_b = lasagne.layers.BatchNormLayer(l_action_head_a)\n",
    "\n",
    "        l_action_head_c = lasagne.layers.NonlinearityLayer(l_action_head_b, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "\n",
    "        l_action_head_d = lasagne.layers.DenseLayer(l_action_head_c, num_units = output_size, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "        return l_action_head_d\n",
    "\n",
    "    \n",
    "    \n",
    "def ActionHeadLayerf(incoming):\n",
    "    l_action_head_a = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k2, filter_size=(1,1), pad = 'same', untie_biases = False,\n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    l_action_head_b = lasagne.layers.BatchNormLayer(l_action_head_a)\n",
    "\n",
    "    l_action_head_c = lasagne.layers.NonlinearityLayer(l_action_head_b, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_action_head_d = lasagne.layers.DenseLayer(l_action_head_c, num_units = output_size, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return l_action_head_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ValueHeadLayer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, incoming):\n",
    "        l_action_head_a = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k2, filter_size=(1,1), pad = 'same', untie_biases = False,\n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "        l_action_head_b = lasagne.layers.BatchNormLayer(l_action_head_a)\n",
    "\n",
    "        l_action_head_c = lasagne.layers.NonlinearityLayer(l_action_head_b, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "        l_action_head_d = lasagne.layers.DenseLayer(l_action_head_c, num_units = output_size_valuehead, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "        l_action_head_e = lasagne.layers.DenseLayer(l_action_head_d, num_units = 1, nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "\n",
    "        return l_action_head_e\n",
    "    \n",
    "def ValueHeadLayerf(incoming):\n",
    "    l_action_head_a = lasagne.layers.Conv2DLayer(\n",
    "            incoming, num_filters=k2, filter_size=(1,1), pad = 'same', untie_biases = False,\n",
    "            nonlinearity=None,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    l_action_head_b = lasagne.layers.BatchNormLayer(l_action_head_a)\n",
    "\n",
    "    l_action_head_c = lasagne.layers.NonlinearityLayer(l_action_head_b, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_action_head_d = lasagne.layers.DenseLayer(l_action_head_c, num_units = output_size_valuehead, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_action_head_e = lasagne.layers.DenseLayer(l_action_head_d, num_units = 1, nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "\n",
    "    return l_action_head_e\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_policy1():\n",
    "\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 2, 6, 7))\n",
    "\n",
    "    l_base = BaseLayerf(l_in)\n",
    "\n",
    "    l_resid = ResidualTowerLayerf(l_base)\n",
    "\n",
    "    l_action = ActionHeadLayerf(l_resid)\n",
    "\n",
    "    return l_action\n",
    "\n",
    "def cnn_policy2():\n",
    "\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 2, 6, 7))\n",
    "\n",
    "    l_base = BaseLayerf(l_in)\n",
    "\n",
    "    l_resid = ResidualTowerLayerf(l_base)\n",
    "\n",
    "    l_action = ActionHeadLayerf(l_resid)\n",
    "\n",
    "    return l_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cnn_value1():\n",
    "    \n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 2, 6, 7))\n",
    "\n",
    "    l_base = BaseLayerf(l_in)\n",
    "\n",
    "    l_resid = ResidualTowerLayerf(l_base)\n",
    "\n",
    "    l_value = ValueHeadLayerf(l_resid)\n",
    "\n",
    "    return l_value\n",
    "\n",
    "\n",
    "def cnn_value2():\n",
    "    \n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 2, 6, 7))\n",
    "\n",
    "    l_base = BaseLayerf(l_in)\n",
    "\n",
    "    l_resid = ResidualTowerLayerf(l_base)\n",
    "\n",
    "    l_value = ValueHeadLayerf(l_resid)\n",
    "\n",
    "    return l_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives of the cnn functions (not in the calculus sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "def cnn_action_1_pred(inp, network):\n",
    "\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    \n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network, input_var)\n",
    "    \n",
    "    #print(inp.shape)\n",
    "    theano.function([input_var], prediction)(inp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def cnn_action_2_pred(inp, network):\n",
    "\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network, input_var)\n",
    "    \n",
    "    theano.function([input_var], prediction)(inp)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cnn_value_1_pred(inp, network):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    \n",
    "    theano.function([input_var], prediction)(inp)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def cnn_value_2_pred(inp, network):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    \n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    \n",
    "    theano.function([input_var], prediction)(inp)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cnn_action_1_loss(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "def cnn_action_2_loss(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cnn_value_1_loss(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def cnn_value_2_loss(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cnn_action_1_grad(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    \n",
    "    network = cnn_action1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "\n",
    "def cnn_action_2_grad(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cnn_value_1_grad(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "\n",
    "def cnn_value_2_grad(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternative loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_action_1_loss_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def cnn_action_2_loss_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_value_1_loss_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def cnn_value_2_loss_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], loss)(inp, tar)\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cnn_action_1_grad_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def cnn_action_2_grad_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_action2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grad = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cnn_value_1_grad_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value1(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grads = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def cnn_value_2_grad_2(inp, tar):\n",
    "    \n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "\n",
    "    network = cnn_value2(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    loss = prediction\n",
    "    loss = loss.mean()\n",
    "\n",
    "    \n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    grads = lasagne.updates.get_or_compute_grads(loss, params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    theano.function([input_var, target_var], grad)(inp, tar)\n",
    "    \n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
