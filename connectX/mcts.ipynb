{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import datetime\n",
    "from random import choice\n",
    "from math import log\n",
    "from math import sqrt\n",
    "\n",
    "%run board_object.ipynb\n",
    "%run basic_value_policy.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board(object):\n",
    "    def __init__(self):\n",
    "        self.board = create_zero()\n",
    "        self.turn = 1\n",
    "        self.tup = tup_base(create_zero())\n",
    "    def start(self):\n",
    "        return tup(create_zero())   \n",
    "    def current_player(self, state):\n",
    "        return turn_check(board_base(state))\n",
    "    def next_state(self, state, play):\n",
    "        return tup_base(fallext(board_base(state), play, self.current_player(board_base(state))))\n",
    "    def legal_plays(self, statehistory):\n",
    "        state = statehistory[-1]\n",
    "        b = board_base(state)[0]\n",
    "        l = []\n",
    "        for i in range(7):\n",
    "            if b[i] == 0:\n",
    "                l.append(i)\n",
    "        return l\n",
    "    def winner(self, statehistory):\n",
    "        state = statehistory[-1]\n",
    "        w = check_winner(board_base(state))\n",
    "        if w == 1:\n",
    "            return 1\n",
    "        if w == 2:\n",
    "            return 2\n",
    "        v = check_valid(board_base(state))\n",
    "        if v == True:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_moves = 100\n",
    "Seconds = 30\n",
    "C = 1.4\n",
    "mixing = 0.0270310072 \n",
    "A = 0.4\n",
    "\n",
    "\n",
    "b2 = Board()\n",
    "\n",
    "def POLICY(state, board):\n",
    "    return basic_policy(board_base(state), board.current_player(state))\n",
    "\n",
    "def VALUE(state, board):\n",
    "    return basic_value(board_base(state), board.current_player(state))\n",
    "\n",
    "\n",
    "\n",
    "policy_choice = POLICY   \n",
    "value_function = VALUE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"notes: rollout needs to be updated to incorporate policy and value       .    Also, fix def winner in board                \"\"\"\n",
    "\n",
    "class MonteCarlo2(object):\n",
    "    #states are tuples\n",
    "    def __init__(self, board, **kwargs):\n",
    "        # Takes an instance of a Board and optionally some keyword\n",
    "        # arguments.  Initializes the list of game states and the\n",
    "        # statistics tables.\n",
    "        self.board = board\n",
    "        self.states = []\n",
    "        self.leaf_state = 'empty'\n",
    "        self.leaf_value = 'empty'\n",
    "        \n",
    "        seconds = Seconds\n",
    "        self.calculation_time = datetime.timedelta(seconds=seconds)\n",
    "        \n",
    "        \n",
    "        self.max_moves = max_moves\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.wins = {}\n",
    "        self.plays = {}\n",
    "        self.C = 1.4\n",
    "        \n",
    "        \n",
    "        \n",
    "        pass\n",
    "\n",
    "    def update(self, state):\n",
    "        # Takes a game state, and appends it to the history.\n",
    "        self.states.append(state)\n",
    "        pass\n",
    "\n",
    "    def get_play(self):\n",
    "        # Causes the AI to calculate the best move from the\n",
    "        # current game state and return it.\n",
    "        \n",
    "        self.max_depth = 0\n",
    "        state = self.states[-1]\n",
    "        player = self.board.current_player(state)\n",
    "        legal = self.board.legal_plays(self.states[:])\n",
    "\n",
    "        # Bail out early if there is no real choice to be made.\n",
    "        if not legal:\n",
    "            return\n",
    "        if len(legal) == 1:\n",
    "            return legal[0]\n",
    "\n",
    "        games = 0\n",
    "        begin = datetime.datetime.utcnow()\n",
    "        while datetime.datetime.utcnow() - begin < self.calculation_time:\n",
    "            self.run_simulation()\n",
    "            games += 1\n",
    "\n",
    "        moves_states = [(p, self.board.next_state(state, p)) for p in legal]\n",
    "\n",
    "        # Display the number of calls of `run_simulation` and the\n",
    "        # time elapsed.\n",
    "        print (games, datetime.datetime.utcnow() - begin)\n",
    "\n",
    "        # Pick the move with the highest percentage of wins.\n",
    "        percent_wins, move = max(\n",
    "            (self.wins.get((player, S), 0) /\n",
    "             self.plays.get((player, S), 1),\n",
    "             p)\n",
    "            for p, S in moves_states\n",
    "        )\n",
    "\n",
    "        # Display the stats for each possible play.\n",
    "        for x in sorted(\n",
    "            ((100 * self.wins.get((player, S), 0) /\n",
    "              self.plays.get((player, S), 1),\n",
    "              self.wins.get((player, S), 0),\n",
    "              self.plays.get((player, S), 0), p)\n",
    "             for p, S in moves_states),\n",
    "            reverse=True\n",
    "        ):\n",
    "            print(\"{3}: {0:.2f}% ({1} / {2})\".format(*x))\n",
    "\n",
    "        print (\"Maximum depth searched:\", self.max_depth)\n",
    "\n",
    "        return move\n",
    "\n",
    "    def run_simulation(self):\n",
    "        plays, wins = self.plays, self.wins\n",
    "        leaf_state, leaf_value = self.leaf_state, self.leaf_value\n",
    "\n",
    "        visited_states = set()\n",
    "        states_copy = self.states[:]\n",
    "        state = states_copy[-1]\n",
    "        player = self.board.current_player(state)\n",
    "\n",
    "        expand = True\n",
    "        for t in range(1, self.max_moves + 1):\n",
    "            legal = self.board.legal_plays(states_copy)\n",
    "            moves_states = [(p, self.board.next_state(state, p)) for p in legal]\n",
    "\n",
    "            if all(plays.get((player, S)) for p, S in moves_states):\n",
    "                #print('yes')\n",
    "                # If we have stats on all of the legal moves here, use them.\n",
    "                log_total = log(\n",
    "                    sum(plays[(player, S)] for p, S in moves_states))\n",
    "                value, move, state = max(\n",
    "                    ((wins[(player, S)] / plays[(player, S)]) +\n",
    "                     self.C * sqrt(log_total / plays[(player, S)]), p, S)\n",
    "                    for p, S in moves_states\n",
    "                )\n",
    "            else:\n",
    "                # Otherwise, just make an arbitrary decision.\n",
    "                \"\"\"Do we want to set the leaf_state before or after??????????\"\"\"\n",
    "                m = policy_choice(state, self.board)\n",
    "                u = np.random.random_integers(0, 6)\n",
    "                b = np.random.binomial(1, 0.3)\n",
    "                if b == 0:\n",
    "                    move = m\n",
    "                else:\n",
    "                    move = u\n",
    "                state = self.board.next_state(state, move)\n",
    "                leaf_state = state\n",
    "                leaf_value = value_function(state, self.board)\n",
    "\n",
    "            states_copy.append(state)\n",
    "\n",
    "            # `player` here and below refers to the player\n",
    "            # who moved into that particular state.\n",
    "            if expand and (player, state) not in plays:\n",
    "                expand = False\n",
    "                plays[(player, state)] = 0\n",
    "                wins[(player, state)] = 0\n",
    "                if t > self.max_depth:\n",
    "                    self.max_depth = t\n",
    "\n",
    "            visited_states.add((player, state))\n",
    "\n",
    "            player = self.board.current_player(state)\n",
    "            winner = self.board.winner(states_copy)\n",
    "            if winner:\n",
    "                if leaf_state == 'empty':\n",
    "                    leaf_state = state\n",
    "                    leaf_value = value_function(state, self.board)\n",
    "                break\n",
    "\n",
    "        for player, state in visited_states:\n",
    "            if (player, state) not in plays:\n",
    "                continue\n",
    "            plays[(player, state)] += 1\n",
    "            mov = move_count(board_base(state))\n",
    "            fac = A * np.exp(-1 * mixing * mov)\n",
    "            if player == winner:\n",
    "                wins[(player, state)] += 1-fac + (fac) * leaf_value\n",
    "            if (3-player) == winner:\n",
    "                wins[(player, state)] += 0 + (fac) * leaf_value    \n",
    "            if winner == -1:\n",
    "                wins[(player, state)] += (1-fac) * 1/2 + (fac) * leaf_value\n",
    "\n",
    "\n",
    "        self.leaf_state = 'empty'\n",
    "        self.leaf_value = 'empty'        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Board' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0b79245b9d0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMonteCarlo2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtup_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Board' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "b = Board()\n",
    "m = MonteCarlo2(b)\n",
    "board = [[0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [1,1,1,0,0,0,0], [2,2,2,0,0,0,0]]\n",
    "board = [[0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0]]\n",
    "m.states = [tup_base(board)]\n",
    "move = m.get_play()\n",
    "print(\"move = \" + str(move))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts_choose(board):\n",
    "    b = Board()\n",
    "    m = MonteCarlo2(b)\n",
    "    m.states = [tup_base(board)]\n",
    "    move = m.get_play()\n",
    "    return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"notes: rollout needs to be updated to incorporate policy and value       .    Also, fix def winner in board                \"\"\"\n",
    "\n",
    "class MonteCarlo3(object):\n",
    "    #states are tuples\n",
    "    def __init__(self, board, policy_fnc, value_fnc):\n",
    "        # Takes an instance of a Board and optionally some keyword\n",
    "        # arguments.  Initializes the list of game states and the\n",
    "        # statistics tables.\n",
    "        self.board = board\n",
    "        self.states = []\n",
    "        self.leaf_state = 'empty'\n",
    "        self.leaf_value = 'empty'\n",
    "        \n",
    "        seconds = Seconds\n",
    "        self.calculation_time = datetime.timedelta(seconds=seconds)\n",
    "        \n",
    "        \n",
    "        self.max_moves = max_moves\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.wins = {}\n",
    "        self.plays = {}\n",
    "        self.C = 1.4\n",
    "        \n",
    "        self.policy_fnc = policy_fnc\n",
    "        self.value_fnc = value_fnc\n",
    "        \n",
    "        \n",
    "        \n",
    "        pass\n",
    "\n",
    "    def update(self, state):\n",
    "        # Takes a game state, and appends it to the history.\n",
    "        self.states.append(state)\n",
    "        pass\n",
    "\n",
    "    def get_play(self):\n",
    "        # Causes the AI to calculate the best move from the\n",
    "        # current game state and return it.\n",
    "        \n",
    "        self.max_depth = 0\n",
    "        state = self.states[-1]\n",
    "        player = self.board.current_player(state)\n",
    "        legal = self.board.legal_plays(self.states[:])\n",
    "\n",
    "        # Bail out early if there is no real choice to be made.\n",
    "        if not legal:\n",
    "            return\n",
    "        if len(legal) == 1:\n",
    "            return legal[0]\n",
    "\n",
    "        games = 0\n",
    "        begin = datetime.datetime.utcnow()\n",
    "        while datetime.datetime.utcnow() - begin < self.calculation_time:\n",
    "            self.run_simulation()\n",
    "            games += 1\n",
    "\n",
    "        moves_states = [(p, self.board.next_state(state, p)) for p in legal]\n",
    "\n",
    "        # Display the number of calls of `run_simulation` and the\n",
    "        # time elapsed.\n",
    "        print (games, datetime.datetime.utcnow() - begin)\n",
    "\n",
    "        # Pick the move with the highest percentage of wins.\n",
    "        percent_wins, move = max(\n",
    "            (self.wins.get((player, S), 0) /\n",
    "             self.plays.get((player, S), 1),\n",
    "             p)\n",
    "            for p, S in moves_states\n",
    "        )\n",
    "\n",
    "        # Display the stats for each possible play.\n",
    "        for x in sorted(\n",
    "            ((100 * self.wins.get((player, S), 0) /\n",
    "              self.plays.get((player, S), 1),\n",
    "              self.wins.get((player, S), 0),\n",
    "              self.plays.get((player, S), 0), p)\n",
    "             for p, S in moves_states),\n",
    "            reverse=True\n",
    "        ):\n",
    "            print(\"{3}: {0:.2f}% ({1} / {2})\".format(*x))\n",
    "\n",
    "        print (\"Maximum depth searched:\", self.max_depth)\n",
    "\n",
    "        return move\n",
    "\n",
    "    def run_simulation(self):\n",
    "        plays, wins = self.plays, self.wins\n",
    "        leaf_state, leaf_value = self.leaf_state, self.leaf_value\n",
    "\n",
    "        visited_states = set()\n",
    "        states_copy = self.states[:]\n",
    "        state = states_copy[-1]\n",
    "        player = self.board.current_player(state)\n",
    "\n",
    "        expand = True\n",
    "        for t in range(1, self.max_moves + 1):\n",
    "            legal = self.board.legal_plays(states_copy)\n",
    "            moves_states = [(p, self.board.next_state(state, p)) for p in legal]\n",
    "\n",
    "            if all(plays.get((player, S)) for p, S in moves_states):\n",
    "                #print('yes')\n",
    "                # If we have stats on all of the legal moves here, use them.\n",
    "                log_total = log(\n",
    "                    sum(plays[(player, S)] for p, S in moves_states))\n",
    "                value, move, state = max(\n",
    "                    ((wins[(player, S)] / plays[(player, S)]) +\n",
    "                     self.C * sqrt(log_total / plays[(player, S)]), p, S)\n",
    "                    for p, S in moves_states\n",
    "                )\n",
    "            else:\n",
    "                # Otherwise, just make an arbitrary decision.\n",
    "                \"\"\"Do we want to set the leaf_state before or after??????????\"\"\"\n",
    "                m = self.policy_fnc(state, self.board)\n",
    "                u = np.random.random_integers(0, 6)\n",
    "                b = np.random.binomial(1, 0.3)\n",
    "                if b == 0:\n",
    "                    move = m\n",
    "                else:\n",
    "                    move = u\n",
    "                state = self.board.next_state(state, move)\n",
    "                leaf_state = state\n",
    "                leaf_value = self.value_fnc(state, self.board)\n",
    "\n",
    "            states_copy.append(state)\n",
    "\n",
    "            # `player` here and below refers to the player\n",
    "            # who moved into that particular state.\n",
    "            if expand and (player, state) not in plays:\n",
    "                expand = False\n",
    "                plays[(player, state)] = 0\n",
    "                wins[(player, state)] = 0\n",
    "                if t > self.max_depth:\n",
    "                    self.max_depth = t\n",
    "\n",
    "            visited_states.add((player, state))\n",
    "\n",
    "            player = self.board.current_player(state)\n",
    "            winner = self.board.winner(states_copy)\n",
    "            if winner:\n",
    "                if leaf_state == 'empty':\n",
    "                    leaf_state = state\n",
    "                    leaf_value = self.value_fnc(state, self.board)\n",
    "                break\n",
    "\n",
    "        for player, state in visited_states:\n",
    "            if (player, state) not in plays:\n",
    "                continue\n",
    "            plays[(player, state)] += 1\n",
    "            mov = move_count(board_base(state))\n",
    "            fac = A * np.exp(-1 * mixing * mov)\n",
    "            if player == winner:\n",
    "                wins[(player, state)] += 1-fac + (fac) * leaf_value\n",
    "            if (3-player) == winner:\n",
    "                wins[(player, state)] += 0 + (fac) * leaf_value    \n",
    "            if winner == -1:\n",
    "                wins[(player, state)] += (1-fac) * 1/2 + (fac) * leaf_value\n",
    "\n",
    "\n",
    "        self.leaf_state = 'empty'\n",
    "        self.leaf_value = 'empty'        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
