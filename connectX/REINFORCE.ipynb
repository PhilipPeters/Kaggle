{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-74e05ec0f832>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Phil\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-582597b8034e>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "%run CNNtf.ipynb\n",
    "%run config.ipynb\n",
    "%run board_object.ipynb\n",
    "import sys \n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import random\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configs: learning rate, batch size, batch size2, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_move(board_obj_obj, network1, params1_v):\n",
    "    turn = board_obj_obj.turn\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if turn == 1:\n",
    "\n",
    "        #argmax needs to be correctly implemented\n",
    "        #print(loop_model_scores([reformat2(board_obj_obj)], True,  network1, params1_v)[0])\n",
    "        i = [prop_choice(loop_model_scores([reformat2(board_obj_obj)], True,  network1, params1_v)[0])]\n",
    "        #i = np.argmax(loop_model_scores([reformat2(board_obj_obj)], True,  network1, params1_v), axis = 1)\n",
    "        print(i)\n",
    "        board_obj_obj.move(i)\n",
    "    elif turn == 2:\n",
    "        \n",
    "        i = [prop_choice(loop_model_scores([switch_reformat(reformat2(board_obj_obj))], True,  network1, params1_v)[0])]\n",
    "        #i = np.argmax(loop_model_scores([switch_reformat(reformat2(board_obj_obj))], True,  network1, params1_v), axis = 1)\n",
    "        print(i)\n",
    "        board_obj_obj.move(i)\n",
    "    return (board_obj_obj, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WRONG need to somehow keep policy CNN for generation, unless we do them together\"\"\"\n",
    "\n",
    "\n",
    "def policy_move_val(board_obj_obj, network1, params1_v):\n",
    "    turn = board_obj_obj.turn\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if turn == 1:\n",
    "\n",
    "        #argmax needs to be correctly implemented\n",
    "        #print(loop_model_scores([reformat2(board_obj_obj)], True,  network1, params1_v)[0])\n",
    "        i = [prop_choice(loop_model_scores_val([reformat2(board_obj_obj)], True,  network1, params1_v)[0])]\n",
    "        #i = np.argmax(loop_model_scores([reformat2(board_obj_obj)], True,  network1, params1_v), axis = 1)\n",
    "        print(i)\n",
    "        board_obj_obj.move(i)\n",
    "    elif turn == 2:\n",
    "        \n",
    "        i = [prop_choice(loop_model_scores_val([switch_reformat(reformat2(board_obj_obj))], True,  network1, params1_v)[0])]\n",
    "        #i = np.argmax(loop_model_scores([switch_reformat(reformat2(board_obj_obj))], True,  network1, params1_v), axis = 1)\n",
    "        print(i)\n",
    "        board_obj_obj.move(i)\n",
    "    return (board_obj_obj, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_trajectory(network1, params1_v):\n",
    "    \n",
    "    board_obj_obj = board_obj()\n",
    "    states = [board_obj_obj]\n",
    "    target = []\n",
    "    board_obj_obj = board_obj_obj.copy()\n",
    "    while evaluate(board_obj_obj.board) not in [0, 0.5, 1]:\n",
    "        p = policy_move(board_obj_obj, network1, params1_v)\n",
    "        (board_obj_obj, i) = (p[0].copy(), p[1]) \n",
    "        states.append(board_obj_obj)\n",
    "        target.append(i)\n",
    "    outcome = evaluate(board_obj_obj.board)\n",
    "    \n",
    "    \n",
    "    return [states, outcome, target]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_trajectory_val(network1, params1_v, network_policy, params_policy):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return sample_trajectory(network_policy, params_policy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(params1_v, batch_size, network1):\n",
    "    #print(params1_v)\n",
    "    params1_va = params1_v.copy()\n",
    "    for count in range(proper_batch_size):\n",
    "        #print(count)\n",
    "        [states, outcome, target] = sample_trajectory(network1, params1_va)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        for i in range(len(target)):\n",
    "            turn_cur = states[i].turn\n",
    "            #make sure the cnn_action() network in cnn_action_grad function definition body is IMMUTABLE\n",
    "            if turn_cur == 1:\n",
    "                grad = loop_model_grad([reformat2(states[i])], target[i], True, network1, params1_va)\n",
    "                #grad = np.array(grad)\n",
    "            elif turn_cur == 2:\n",
    "                grad = loop_model_grad([switch_reformat(reformat2(states[i]))], target[i], True, network1, params1_va)\n",
    "                #grad = np.array(grad)\n",
    "            else:\n",
    "                print('Turn Error')\n",
    "                sys.exit()\n",
    "\n",
    "            if turn_cur == 1:\n",
    "                #for param, grad_ind in zip(params1, grad):\n",
    "                    #updates1[param] = param + learning_rate * grad_ind * outcome\n",
    "                grad = np.array(grad)\n",
    "                params1_va = np.array(params1_va)\n",
    "                params1_va = params1_va - learning_rate * grad * outcome    \n",
    "            elif turn_cur == 2:\n",
    "                #for param, grad_ind in zip(params2, grad):\n",
    "                    #updates2[param] = param + learning_rate * grad_ind * outcome\n",
    "                grad = np.array(grad)\n",
    "                params1_va = np.array(params1_va)\n",
    "                params1_va = params1_va - learning_rate * grad * (1 - outcome)     \n",
    "            else:\n",
    "                print('Turn Error')\n",
    "                sys.exit()\n",
    "                \n",
    "               \n",
    "        print('one_loop_done')\n",
    "    print(params1_va[0][0][0])\n",
    "    print('break')\n",
    "    print(params1_v[0][0][0])\n",
    "    return params1_va\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "def iteration_action(params1_v, batch_size, network1):\n",
    "    #print(params1_v)\n",
    "    params1_va = params1_v.copy()\n",
    "    \n",
    "    \n",
    "    #need to add something that sets graph to pol graph\n",
    "    pipe = test_RESIDUAL_net_action_1([1])\n",
    "    \n",
    "    network_pol = RESIDUAL_net_action_1\n",
    "    params_pol = loop_model_params_get(True, network_pol)\n",
    "    for count in range(proper_batch_size):\n",
    "        #print(count)\n",
    "        [states, outcome, target] = sample_trajectory(network_pol, params_pol)\n",
    "\n",
    "\n",
    "        T = len(target)-1\n",
    "        i = random.choice(list(range(T)))\n",
    "        choice_2 = random.choice(list(range(T)))\n",
    "        \n",
    "        \n",
    "        turn_cur = states[i].turn\n",
    "        \n",
    "        \n",
    "        #make sure the cnn_action() network in cnn_action_grad function definition body is IMMUTABLE\n",
    "        if turn_cur == 1:\n",
    "            loss, grad = loop_model_grad_alt([reformat2(states[i])], True, network1, params1_va)\n",
    "            #grad = np.array(grad)\n",
    "        elif turn_cur == 2:\n",
    "            loss, grad = loop_model_grad_alt([switch_reformat(reformat2(states[i]))], True, network1, params1_va)\n",
    "            #grad = np.array(grad)\n",
    "        else:\n",
    "            print('Turn Error')\n",
    "            sys.exit()\n",
    "\n",
    "        \n",
    "        ###Need to fix gradient update\n",
    "        \n",
    "        \n",
    "        \n",
    "        if turn_cur == 1:\n",
    "            #for param, grad_ind in zip(params1, grad):\n",
    "                #updates1[param] = param + learning_rate * grad_ind * outcome\n",
    "            grad = np.array(grad)\n",
    "            params1_va = np.array(params1_va)\n",
    "            params1_va = params1_va + learning_rate * grad * (outcome - loss)    \n",
    "        elif turn_cur == 2:\n",
    "            #for param, grad_ind in zip(params2, grad):\n",
    "                #updates2[param] = param + learning_rate * grad_ind * outcome\n",
    "            grad = np.array(grad)\n",
    "            params1_va = np.array(params1_va)\n",
    "            params1_va = params1_va + learning_rate * grad * (1 - outcome - loss)     \n",
    "        else:\n",
    "            print('Turn Error')\n",
    "            sys.exit()\n",
    "\n",
    "               \n",
    "        print('one_loop_done')\n",
    "    print(params1_va[0][0][0])\n",
    "    print('break')\n",
    "    print(params1_v[0][0][0])\n",
    "    return params1_va\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def REINFORCEloop(epochs):\n",
    "    network1 = RESIDUAL_net_action_1\n",
    "    pipe = test_RESIDUAL_net_action_1([1])\n",
    "    for i in range(epochs):\n",
    "        #print(i)\n",
    "        params1 = loop_model_params_get(True, network1)\n",
    "        u = iteration(params1, batch_size, network1).copy()\n",
    "        loop_model_params_set(True, network1, u)\n",
    "        \n",
    "        \n",
    "    return network1\n",
    "\n",
    "\n",
    "def Valueloop(epochs):\n",
    "    network1 = RESIDUAL_net_value_1\n",
    "    pipe = test_RESIDUAL_net_value_1([1])\n",
    "    for i in range(epochs):\n",
    "        #print(i)\n",
    "        params1 = loop_model_params_get(True, network1)\n",
    "        u = iteration_action(params1, batch_size, network1).copy()\n",
    "        loop_model_params_set(True, network1, u)\n",
    "        \n",
    "        \n",
    "    return network1\n",
    "\n",
    "def REINFORCEloop2(epochs):\n",
    "    network1 = RESIDUAL_net_action_1\n",
    "    pipe = test_RESIDUAL_net_action_1([1])\n",
    "    for i in range(epochs):\n",
    "        #print(i)\n",
    "        params1 = loop_model_params_get(True, network1)\n",
    "        u = iteration(params1, batch_size, network1).copy()\n",
    "        loop_model_params_set(True, network1, u)\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open('policy_model.pkl', 'wb') as file:\n",
    "        pickle.dump(params1, file)\n",
    "\n",
    "    with open('policy_model.pkl', 'rb') as file:\n",
    "        params1 = pickle.load(file)\n",
    "        \n",
    "    return network1\n",
    "\n",
    "\n",
    "def Valueloop2(epochs):\n",
    "    network1 = RESIDUAL_net_value_1\n",
    "    pipe = test_RESIDUAL_net_value_1([1])\n",
    "    for i in range(epochs):\n",
    "        #print(i)\n",
    "        params1 = loop_model_params_get(True, network1)\n",
    "        u = iteration_action(params1, batch_size, network1).copy()\n",
    "        loop_model_params_set(True, network1, u)\n",
    "    \n",
    "    \n",
    "    with open('value_model.pkl', 'wb') as file:\n",
    "        pickle.dump(params1, file)\n",
    "\n",
    "    with open('value_model.pkl', 'rb') as file:\n",
    "        params1 = pickle.load(file)\n",
    "        \n",
    "    return network1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
